# https://github.com/stevekm/pg-elk/blob/master/config/logstash.conf
input {
    beats {
        # port to listen for Filebeat messages
        port => "5044"
    }
}

filter {
    mutate {
        copy => { "id" => "[@metadata][_id]"}
        # copy => { "tissue" => "[@metadata][_tissue]"}
        # copy => { "coverage" => "[@metadata][_coverage]"}
        # copy => { "created" => "[@metadata][_created]"}
        # copy => { "sampleid" => "[@metadata][_sampleid]"}
    }
}

output {
    # push a copy of each event to ElasticSearch
    # https://www.elastic.co/guide/en/logstash/current/plugins-outputs-elasticsearch.html
    elasticsearch {
        hosts => ["${ES_URL}"] # get this from exported environment variables #["http://${ES_HOST}:${ES_PORT}"]
        index => "${ES_INDEX}"
        document_id => "%{id}"
        # doc_as_upsert => true
        #user => “es_user”
        #password => “es_password”
    }

    # pretty-print a copy of each event + metadata to console stdou
    # https://www.elastic.co/guide/en/logstash/current/plugins-outputs-stdout.html
    stdout { codec => rubydebug }
    # stdout { codec => rubydebug { metadata => true } }
    # stdout { codec => json }

    # save a copy of each event in a file
    # file {
    #     path => "${LOG_DIR}/logstash_log_outputs.txt"
    # }
}
